{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Models\n",
    "This notebook contains the code for various SVM models used to classify images as melanoma or as benign. \n",
    "\n",
    "A variety of SVM models were used with the following kernels: RBF (radial basis function), linear and poly.\n",
    "\n",
    "The SVM models were modelled using scikit-learn and tensorflow libraries in Python.\n",
    "\n",
    "You'll see blocks of code commented out completely in this version --these are the initial feature engineering blocks which resized images. The process of resizing over 30,000 images and converting to vector values was time consuming, so a CSV was created that contains the appropriate data. The code which created the csv file is commented out.\n",
    "\n",
    "Ultimately, the preferred model using the SVM method was determined early on, a SVM model using an RBF kernel and equal amounts of benign and malignant (melanoma) data in the training set lead to the most balanced results in terms of classifying the different classes when tested against a dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "colab_type": "code",
    "id": "unDZ8CE0mEa_",
    "outputId": "b998464f-68ee-4534-e01a-6b9ab3ee7d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
      "\u001b[K     |████████████████████████████████| 412.3MB 44kB/s \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 56.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.30.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 54.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (49.2.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=821828eb1c3e10c6564999a4ec2983fe274ae09a019cbcd66c98abe9543ee808\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow\n",
      "  Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "EWBEM_KLtyft",
    "outputId": "19745f86-4c3b-4de6-e679-6c61cf3b7b02"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'import tensorflow as tf\\n\\nimport os\\nimport tensorflow_datasets as tfds\\n\\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\\'grpc://\\' + os.environ[\\'COLAB_TPU_ADDR\\'])\\ntf.config.experimental_connect_to_cluster(resolver)\\n# This is the TPU initialization code that has to be at the beginning.\\ntf.tpu.experimental.initialize_tpu_system(resolver)\\n#print(\"All devices: \", tf.config.list_logical_devices(\\'TPU\\'))\\n\\n#a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\\n#b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\\n##with tf.device(\\'/TPU:0\\'):\\n#  c = tf.matmul(a, b)\\n#print(\"c device: \", c.device)\\n#print(c)\\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "#print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "#a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "#b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "##with tf.device('/TPU:0'):\n",
    "#  c = tf.matmul(a, b)\n",
    "#print(\"c device: \", c.device)\n",
    "#print(c)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "WrZfw4nCQI_G",
    "outputId": "ea1355a3-efab-4880-ce24-bff2764a981d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-resize-image\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/89/008481c95551992e1a77503eba490b75fd17c0a98e33dd4dc39e0b99e5e8/python_resize_image-1.1.19-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Pillow>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from python-resize-image) (7.0.0)\n",
      "Requirement already satisfied: requests>=2.19.1 in /usr/local/lib/python3.6/dist-packages (from python-resize-image) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.1->python-resize-image) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.1->python-resize-image) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.1->python-resize-image) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.1->python-resize-image) (2.10)\n",
      "Installing collected packages: python-resize-image\n",
      "Successfully installed python-resize-image-1.1.19\n"
     ]
    }
   ],
   "source": [
    "!pip install python-resize-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jIvfbhiRQKj5",
    "outputId": "f48900d5-512a-4660-fe71-daa02f49488c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "DPGFe6TnHQf6",
    "outputId": "93864f56-a70a-4628-a570-6724e1922c25"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'# local vs. colab\\nIS_LOCAL = False\\n\\n\\nKAGGLE_TFREC_GCS ={\\n        128: \\'gs://kds-659708bf9143f303ebfd1c862eb9e842090662d9004190208d007cc9\\',\\n        192: \\'gs://kds-f53b5775dce9868747163621afd1adc2815412f220130261292837a3\\',\\n        256: \\'gs://kds-f64cfd42bcb769b2eeeecd53d5a52df83d43c19c1184989ed762e30f\\',\\n        384: \\'gs://kds-e73569ee9d44308363027e79908294593e80b1e12e18e57ef065397c\\',\\n        512: \\'gs://kds-4f5e437bc05e29f3e95419fa289ea3a6b01ac2fefcb772ca07cc3b5f\\',\\n        768: \\'gs://kds-49b793da52a884d00e33c11613f3f24261d8e53e1b8c16de8c868509\\'}\\n\\n# colab online\\nPATH_KAGGLE_MEL = \\'/content/gdrive/My Drive/Kaggle/melanoma/\\'\\nREPO_ROOT = \\'/content/gdrive/My Drive/Kaggle/melanoma/\\'\\nREPO_TEMP = REPO_ROOT + \\'temp/\\'\\n    \\n# mount google drive on colab\\ndrive.mount(\\'/content/gdrive\\')\\n\\nwarnings.filterwarnings(\"ignore\") # suppress warning messages\\nplt.style.use(\\'ggplot\\')\\n\\nPROCESSOR = \"GPU\" if IS_LOCAL else \"TPU\"\\nSEED = 207 # used for creating k-fold\\nif PROCESSOR == \"TPU\":\\n    print(\"connecting to TPU...\")\\n    #try:\\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\\n    print(\\'Running on TPU: \\', tpu.master())\\n    #except ValueError:\\n    print(\"Error: Unable to connect to TPU...\")\\n    tpu = None\\n\\n    if tpu:\\n        #try:\\n          print(\"Initializing TPU...\")\\n          tf.config.experimental_connect_to_cluster(tpu)\\n          tf.tpu.experimental.initialize_tpu_system(tpu)\\n          strategy = tf.distribute.experimental.TPUStrategy(tpu)\\n          print(\"TPU initialized!\")\\n        #except _:\\n          print(\"Error: Failed to initialize TPU...\")\\n    else:\\n        PROCESSOR = \"GPU\"\\n\\nif PROCESSOR != \"TPU\":\\n    print(\"Using default strategy for CPU/GPU...\")\\n    strategy = tf.distribute.get_strategy()\\n\\nif PROCESSOR == \"GPU\":\\n    print(\"# of GPUs Available: \", len(tf.config.experimental.list_physical_devices(\\'GPU\\')))\\n            \\n# https://tinyurl.com/yao4obsb\\n# A single Cloud TPU device consists of four chips, each of which has two TPU cores. \\n# Therefore, for efficient utilization of Cloud TPU, a program should make use of \\n# each of the eight cores.\\nREPLICAS = strategy.num_replicas_in_sync\\nprint(f\\'# of replicatas in sync: {REPLICAS}\\')'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# local vs. colab\n",
    "IS_LOCAL = False\n",
    "\n",
    "\n",
    "KAGGLE_TFREC_GCS ={\n",
    "        128: 'gs://kds-659708bf9143f303ebfd1c862eb9e842090662d9004190208d007cc9',\n",
    "        192: 'gs://kds-f53b5775dce9868747163621afd1adc2815412f220130261292837a3',\n",
    "        256: 'gs://kds-f64cfd42bcb769b2eeeecd53d5a52df83d43c19c1184989ed762e30f',\n",
    "        384: 'gs://kds-e73569ee9d44308363027e79908294593e80b1e12e18e57ef065397c',\n",
    "        512: 'gs://kds-4f5e437bc05e29f3e95419fa289ea3a6b01ac2fefcb772ca07cc3b5f',\n",
    "        768: 'gs://kds-49b793da52a884d00e33c11613f3f24261d8e53e1b8c16de8c868509'}\n",
    "\n",
    "# colab online\n",
    "PATH_KAGGLE_MEL = '/content/gdrive/My Drive/Kaggle/melanoma/'\n",
    "REPO_ROOT = '/content/gdrive/My Drive/Kaggle/melanoma/'\n",
    "REPO_TEMP = REPO_ROOT + 'temp/'\n",
    "    \n",
    "# mount google drive on colab\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # suppress warning messages\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "PROCESSOR = \"GPU\" if IS_LOCAL else \"TPU\"\n",
    "SEED = 207 # used for creating k-fold\n",
    "if PROCESSOR == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    #try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU: ', tpu.master())\n",
    "    #except ValueError:\n",
    "    print(\"Error: Unable to connect to TPU...\")\n",
    "    tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        #try:\n",
    "          print(\"Initializing TPU...\")\n",
    "          tf.config.experimental_connect_to_cluster(tpu)\n",
    "          tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "          strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "          print(\"TPU initialized!\")\n",
    "        #except _:\n",
    "          print(\"Error: Failed to initialize TPU...\")\n",
    "    else:\n",
    "        PROCESSOR = \"GPU\"\n",
    "\n",
    "if PROCESSOR != \"TPU\":\n",
    "    print(\"Using default strategy for CPU/GPU...\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if PROCESSOR == \"GPU\":\n",
    "    print(\"# of GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "            \n",
    "# https://tinyurl.com/yao4obsb\n",
    "# A single Cloud TPU device consists of four chips, each of which has two TPU cores. \n",
    "# Therefore, for efficient utilization of Cloud TPU, a program should make use of \n",
    "# each of the eight cores.\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'# of replicatas in sync: {REPLICAS}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "v3d2bU6qr3TM",
    "outputId": "d550fe77-ba41-4896-b306-e9d88f116fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/My Drive/Kaggle/melanoma/jpeg/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "inlA5URCQMYA",
    "outputId": "e13d124b-a2b0-4123-e9fa-726382236e6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  ...  diagnosis benign_malignant target\n",
       "0  ISIC_2637011  IP_7279968    male  ...    unknown           benign      0\n",
       "1  ISIC_0015719  IP_3075186  female  ...    unknown           benign      0\n",
       "2  ISIC_0052212  IP_2842074  female  ...      nevus           benign      0\n",
       "3  ISIC_0068279  IP_6890425  female  ...    unknown           benign      0\n",
       "4  ISIC_0074268  IP_8723313  female  ...    unknown           benign      0\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv=pd.read_csv('/content/gdrive/My Drive/Kaggle/melanoma/csv/train.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "pHr-FyQZQRob",
    "outputId": "6c87402d-000d-4423-e20d-bf533b3b44e0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F59964E9F28>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/ISIC_0015719.jpg\")\n",
    "img=img.resize((32, 32))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNKeoIzAQkE2"
   },
   "source": [
    "Support Vector Machines are supervised learning models which are often used in classification, regression, and outlier detection. They are effective in high dimesnional spaces, and still effective in cases where the number of dimensions is greater than the number of samples. A subset of training points are used in the decision function, called support vectors, which is beneficial in terms of memory efficiency. The ability to use different kernel functions makes this model versatile. Common kernels are provided in Python packages, but it's also possible to specify custom-made kernels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "Hk70r0pnWlNv",
    "outputId": "4f66ccde-604a-4c1c-9f4e-31438f48786f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ISIC_0149568</td>\n",
       "      <td>IP_0962375</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ISIC_0188432</td>\n",
       "      <td>IP_0135517</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>ISIC_0207268</td>\n",
       "      <td>IP_7735373</td>\n",
       "      <td>male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>ISIC_0232101</td>\n",
       "      <td>IP_8349964</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ISIC_0247330</td>\n",
       "      <td>IP_3232631</td>\n",
       "      <td>female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32969</th>\n",
       "      <td>ISIC_9955163</td>\n",
       "      <td>IP_7507212</td>\n",
       "      <td>male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33000</th>\n",
       "      <td>ISIC_9963177</td>\n",
       "      <td>IP_1165806</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33014</th>\n",
       "      <td>ISIC_9967383</td>\n",
       "      <td>IP_7887363</td>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33050</th>\n",
       "      <td>ISIC_9978107</td>\n",
       "      <td>IP_2860540</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33117</th>\n",
       "      <td>ISIC_9998682</td>\n",
       "      <td>IP_2516168</td>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  patient_id     sex  ...  diagnosis benign_malignant target\n",
       "91     ISIC_0149568  IP_0962375  female  ...   melanoma        malignant      1\n",
       "235    ISIC_0188432  IP_0135517  female  ...   melanoma        malignant      1\n",
       "314    ISIC_0207268  IP_7735373    male  ...   melanoma        malignant      1\n",
       "399    ISIC_0232101  IP_8349964    male  ...   melanoma        malignant      1\n",
       "459    ISIC_0247330  IP_3232631  female  ...   melanoma        malignant      1\n",
       "...             ...         ...     ...  ...        ...              ...    ...\n",
       "32969  ISIC_9955163  IP_7507212    male  ...   melanoma        malignant      1\n",
       "33000  ISIC_9963177  IP_1165806    male  ...   melanoma        malignant      1\n",
       "33014  ISIC_9967383  IP_7887363    male  ...   melanoma        malignant      1\n",
       "33050  ISIC_9978107  IP_2860540    male  ...   melanoma        malignant      1\n",
       "33117  ISIC_9998682  IP_2516168    male  ...   melanoma        malignant      1\n",
       "\n",
       "[584 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv[train_csv['target']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUa2RPx458BU"
   },
   "outputs": [],
   "source": [
    "malignant_df=train_csv[train_csv['target']==1][:500]\n",
    "benign_df=train_csv[train_csv['target']==0][:30000].sample(n=500)\n",
    "\n",
    "malignant_df_dev=train_csv[train_csv['target']==1][500:]\n",
    "benign_df_dev=train_csv[train_csv['target']==0][30000:30500].sample(n=len(malignant_df_dev))\n",
    "\n",
    "train_labels_mal=malignant_df['target'].tolist()\n",
    "image_names_mal=malignant_df['image_name'].tolist()\n",
    "train_labels_ben=benign_df['target'].tolist()\n",
    "image_names_ben=benign_df['image_name'].tolist()\n",
    "\n",
    "dev_labels_mal=malignant_df_dev['target'].tolist()\n",
    "dev_image_names_mal=malignant_df_dev['image_name'].tolist()\n",
    "dev_labels_ben=benign_df_dev['target'].tolist()\n",
    "dev_image_names_ben=benign_df_dev['image_name'].tolist()\n",
    "train_labels=[1 for image in image_names_mal]+[0 for image in image_names_ben]\n",
    "dev_labels=[1 for image in dev_image_names_mal]+[0 for image in dev_image_names_ben]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3vVlgsbXW9x"
   },
   "source": [
    "In the case of this dataset, when target==1, the image of the mole is a melanoma and when target==0, the image of the model is non-malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwQ0uxAg3En1"
   },
   "source": [
    "###Initial SVM Model Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ryai3vwQ36G_",
    "outputId": "3f0deb78-98ee-42ed-abb0-83dfcdc24ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square Side Length=64, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73        84\n",
      "           1       0.71      0.86      0.78        84\n",
      "\n",
      "    accuracy                           0.76       168\n",
      "   macro avg       0.77      0.76      0.75       168\n",
      "weighted avg       0.77      0.76      0.75       168\n",
      "\n",
      "AUC 0.7559523809523809\n",
      "Square Side Length=64, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        84\n",
      "           1       0.73      0.69      0.71        84\n",
      "\n",
      "    accuracy                           0.72       168\n",
      "   macro avg       0.72      0.72      0.72       168\n",
      "weighted avg       0.72      0.72      0.72       168\n",
      "\n",
      "AUC 0.7202380952380952\n",
      "Square Side Length=64, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68        84\n",
      "           1       0.68      0.85      0.75        84\n",
      "\n",
      "    accuracy                           0.72       168\n",
      "   macro avg       0.73      0.72      0.72       168\n",
      "weighted avg       0.73      0.72      0.72       168\n",
      "\n",
      "AUC 0.7202380952380952\n",
      "Square Side Length=32, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73        84\n",
      "           1       0.71      0.86      0.78        84\n",
      "\n",
      "    accuracy                           0.76       168\n",
      "   macro avg       0.77      0.76      0.75       168\n",
      "weighted avg       0.77      0.76      0.75       168\n",
      "\n",
      "AUC 0.7559523809523809\n",
      "Square Side Length=32, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70        84\n",
      "           1       0.71      0.63      0.67        84\n",
      "\n",
      "    accuracy                           0.68       168\n",
      "   macro avg       0.69      0.68      0.68       168\n",
      "weighted avg       0.69      0.68      0.68       168\n",
      "\n",
      "AUC 0.6845238095238095\n",
      "Square Side Length=32, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69        84\n",
      "           1       0.69      0.83      0.75        84\n",
      "\n",
      "    accuracy                           0.73       168\n",
      "   macro avg       0.74      0.73      0.72       168\n",
      "weighted avg       0.74      0.73      0.72       168\n",
      "\n",
      "AUC 0.7261904761904763\n"
     ]
    }
   ],
   "source": [
    "square_side_lengths=[64,32]\n",
    "\n",
    "for square_side_length in square_side_lengths:\n",
    "  train_data=[]\n",
    "  train_labels=[]\n",
    "  num_mal=0\n",
    "  num_benign=0\n",
    "  for image in image_names_mal:\n",
    "    try:\n",
    "      im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\n",
    "      im=array(im.resize((square_side_length, square_side_length)))\n",
    "      train_data.append(im)\n",
    "      train_labels.append(1)\n",
    "      num_mal+=1\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  for image in image_names_ben:\n",
    "      try:\n",
    "        im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image)) #\"/content/gdrive/My Drive/Kaggle/melanoma/jpeg_compressed/q_60/train/{}.jpg\"\n",
    "        im=array(im.resize((square_side_length, square_side_length)))\n",
    "        train_data.append(im)\n",
    "        train_labels.append(0)\n",
    "        num_benign+=1\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "\n",
    "  dev_data=[]\n",
    "  dev_labels=[]\n",
    "  num_mal=0\n",
    "  num_benign=0\n",
    "  for image in dev_image_names_mal:\n",
    "    try:\n",
    "      im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\n",
    "      im=array(im.resize((square_side_length, square_side_length)))\n",
    "      dev_data.append(im)\n",
    "      dev_labels.append(1)\n",
    "      num_mal+=1\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  for image in dev_image_names_ben:\n",
    "      try:\n",
    "        im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\n",
    "        im=array(im.resize((square_side_length, square_side_length)))\n",
    "        dev_data.append(im)\n",
    "        dev_labels.append(0)\n",
    "        num_benign+=1\n",
    "      except:\n",
    "        pass\n",
    "    \n",
    "  target_names=[str(x) for x in list(np.unique(dev_labels))]\n",
    "\n",
    "  train_data=array(train_data)\n",
    "  dev_data=array(dev_data)\n",
    "  X_train = train_data.reshape(train_data.shape[0], square_side_length, square_side_length, 3)\n",
    "  X_dev = dev_data.reshape(dev_data.shape[0], square_side_length, square_side_length, 3)\n",
    "  X_train = X_train.astype('float32')\n",
    "  X_dev = X_dev.astype('float32')\n",
    "\n",
    "  X_train /= 255\n",
    "  X_dev /= 255\n",
    "\n",
    "  Y_train = np_utils.to_categorical(train_labels, 2)\n",
    "  Y_dev = np_utils.to_categorical(dev_labels, 2)\n",
    "\n",
    "  X_train_svm=[]\n",
    "  for i in X_train:\n",
    "    nsamples, nx, ny = i.shape\n",
    "    d2_train_dataset = i.reshape((nsamples*nx*ny))\n",
    "    X_train_svm.append(d2_train_dataset)\n",
    "\n",
    "  X_dev_svm=[]\n",
    "  for i in X_dev:\n",
    "    nsamples, nx, ny = i.shape\n",
    "    d2_train_dataset = i.reshape((nsamples*nx*ny))\n",
    "    X_dev_svm.append(d2_train_dataset)\n",
    "\n",
    "  for kern in ('rbf','linear', 'poly'):\n",
    "    svm = make_pipeline(StandardScaler(), SVC(kernel=kern,gamma='auto'))\n",
    "    svm.fit(X_train_svm, train_labels)\n",
    "    prediction_svm=svm.predict(X_dev_svm) #predicting with dev_data\n",
    "    print(\"Square Side Length={}, Kernel={}\".format(square_side_length,kern))\n",
    "    print(classification_report(dev_labels, prediction_svm, target_names=target_names)) #printing classification report to get key result\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels, prediction_svm, pos_label=1)\n",
    "    print(\"AUC\",metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GbVvUVh5BpEo"
   },
   "source": [
    "Increasing the square side length of images reduced accuracy. Smaller images will be used moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hb8lPUrqCd6T"
   },
   "source": [
    "### Tensorflow Model with Reduced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "w5o-VHTBB8J2",
    "outputId": "4c46d031-65e9-4f6b-93e7-ef5b48b78a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/svm.py:153: binary_svm_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/svm.py:153: binary_svm_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpv9yr_qmy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpv9yr_qmy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f59963e8400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpv9yr_qmy', '_session_creation_timeout_secs': 7200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f59963e8400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpv9yr_qmy', '_session_creation_timeout_secs': 7200}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/linear_optimizer/python/sdca_optimizer.py:276: SdcaModel.__init__ (from tensorflow.contrib.linear_optimizer.python.ops.sdca_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated. To UPDATE or USE linear optimizers, please check its latest version in core: tensorflow_estimator/python/estimator/canned/linear_optimizer/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/linear_optimizer/python/sdca_optimizer.py:276: SdcaModel.__init__ (from tensorflow.contrib.linear_optimizer.python.ops.sdca_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated. To UPDATE or USE linear optimizers, please check its latest version in core: tensorflow_estimator/python/estimator/canned/linear_optimizer/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/linear_optimizer/python/ops/sdca_ops.py:169: ShardedMutableDenseHashTable.__init__ (from tensorflow.contrib.linear_optimizer.python.ops.sharded_mutable_dense_hashtable) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated. To UPDATE or USE linear optimizers, please check its latest version in core: tensorflow_estimator/python/estimator/canned/linear_optimizer/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/linear_optimizer/python/ops/sdca_ops.py:169: ShardedMutableDenseHashTable.__init__ (from tensorflow.contrib.linear_optimizer.python.ops.sharded_mutable_dense_hashtable) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated. To UPDATE or USE linear optimizers, please check its latest version in core: tensorflow_estimator/python/estimator/canned/linear_optimizer/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpv9yr_qmy/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpv9yr_qmy/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.93844235, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.93844235, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpv9yr_qmy/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpv9yr_qmy/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.9013876.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.9013876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-08-02T18:28:51Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-08-02T18:28:51Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv9yr_qmy/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv9yr_qmy/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-08-02-18:28:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-08-02-18:28:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.5722656, global_step = 100, loss = 0.876158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.5722656, global_step = 100, loss = 0.876158\n"
     ]
    }
   ],
   "source": [
    "#train_data=array(train_data_list)\n",
    "#dev_data=array(dev_data_list)\n",
    "#X_train = train_data.reshape(train_data.shape[0], 32, 32, 3)\n",
    "#X_dev = dev_data.reshape(dev_data.shape[0], 32, 32, 3)\n",
    "X_train = X_train.astype('float32')\n",
    "X_dev = X_dev.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_dev /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(train_labels, 2)\n",
    "Y_dev = np_utils.to_categorical(dev_labels, 2)\n",
    "\n",
    "X_train_svm=[]\n",
    "for i in X_train:\n",
    "  nsamples, nx, ny = i.shape\n",
    "  d2_train_dataset = i.reshape((nsamples*nx*ny))\n",
    "  X_train_svm.append(d2_train_dataset)\n",
    "\n",
    "X_dev_svm=[]\n",
    "for i in X_dev:\n",
    "  nsamples, nx, ny = i.shape\n",
    "  d2_train_dataset = i.reshape((nsamples*nx*ny))\n",
    "  X_dev_svm.append(d2_train_dataset)\n",
    "\n",
    "target_names=[str(x) for x in list(np.unique(dev_labels))]\n",
    "\n",
    "#https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/learn/python/learn/estimators/svm.py\n",
    "X = np.array(X_train_svm)\n",
    "Y = np.array(train_labels)\n",
    "\n",
    "X_dev=np.array(X_dev_svm)\n",
    "Y_dev=np.array(dev_labels)\n",
    "\n",
    "example_id = np.array(['%d' % i for i in range(len(Y))])\n",
    "example_id_dev = np.array(['%d' % i for i in range(len(Y_dev))])\n",
    "\n",
    "x_column_name = 'x'\n",
    "example_id_column_name = 'example_id'\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={x_column_name: X, example_id_column_name: example_id},\n",
    "    y=Y,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "dev_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={x_column_name: X_dev, example_id_column_name: example_id_dev},\n",
    "    y=Y_dev,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "svm = tf.contrib.learn.SVM(\n",
    "    example_id_column=example_id_column_name,\n",
    "    feature_columns=(tf.contrib.layers.real_valued_column(\n",
    "        column_name=x_column_name, dimension=49152),),\n",
    "    l2_regularization=1)\n",
    "\n",
    "svm.fit(input_fn=train_input_fn, steps=100)\n",
    "svm_metrics = svm.evaluate(input_fn=dev_input_fn, steps=100)\n",
    "#auc=metrics=[tf.keras.metrics.AUC()]\n",
    "#svm_predictions=[x for x in svm.predict_classes(input_fn=dev_input_fn)]\n",
    "\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(dev_labels, svm_predictions, pos_label=1)\n",
    "#print(\"AUC\",metrics.auc(fpr, tpr))\n",
    "#print(\"Loss\", svm_metrics['loss'], \"\\nAccuracy\", svm_metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlbjcIW7WhxA"
   },
   "outputs": [],
   "source": [
    "#malignant_df=train_csv[train_csv['target']==1][:500]\n",
    "benign_df=train_csv[train_csv['target']==0][:30000]#.sample(n=500)\n",
    "\n",
    "#malignant_df_dev=train_csv[train_csv['target']==1][500:]\n",
    "benign_df_dev=train_csv[train_csv['target']==0][30000:30500]#.sample(n=len(malignant_df_dev))\n",
    "\n",
    "#train_labels_mal=malignant_df['target'].tolist()\n",
    "#image_names_mal=malignant_df['image_name'].tolist()\n",
    "train_labels_ben=benign_df['target'].tolist()\n",
    "image_names_ben=benign_df['image_name'].tolist()\n",
    "\n",
    "#dev_labels_mal=malignant_df_dev['target'].tolist()\n",
    "#dev_image_names_mal=malignant_df_dev['image_name'].tolist()\n",
    "dev_labels_ben=benign_df_dev['target'].tolist()\n",
    "dev_image_names_ben=benign_df_dev['image_name'].tolist()\n",
    "train_labels=[1 for image in image_names_mal]+[0 for image in image_names_ben]\n",
    "dev_labels=[1 for image in dev_image_names_mal]+[0 for image in dev_image_names_ben]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "1gJPzk-LXWOc",
    "outputId": "c5a7ef5d-4006-4e1a-cbab-a27db7d774cb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'train_data=[]\\n\\nfor image in image_names_mal:\\n  try:\\n    im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\\n    im=array(im.resize((32, 32)))\\n    train_data.append(im)\\n  except:\\n    pass\\n\\n\\n \\nfor image in image_names_ben:\\n    try:\\n      im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image)) #\"/content/gdrive/My Drive/Kaggle/melanoma/jpeg_compressed/q_60/train/{}.jpg\"\\n      im=array(im.resize((32, 32)))\\n      train_data.append(im)\\n    except:\\n      pass\\n\\ntrain_df=pd.DataFrame(columns=[\\'image #\\']+[str(x+1) for x in range(32)])\\nfor i in range(len(train_data)):\\n  img=train_data[i]\\n  for j in range(len(img)):\\n    train_df.loc[i,\\'image #\\']=i\\n    train_df.loc[i,str(j+1)]=img[j].reshape(32*3)\\n\\ntrain_df.to_csv(\"train_data.csv\")'"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_data=[]\n",
    "\n",
    "for image in image_names_mal:\n",
    "  try:\n",
    "    im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\n",
    "    im=array(im.resize((32, 32)))\n",
    "    train_data.append(im)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    " \n",
    "for image in image_names_ben:\n",
    "    try:\n",
    "      im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image)) #\"/content/gdrive/My Drive/Kaggle/melanoma/jpeg_compressed/q_60/train/{}.jpg\"\n",
    "      im=array(im.resize((32, 32)))\n",
    "      train_data.append(im)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "train_df=pd.DataFrame(columns=['image #']+[str(x+1) for x in range(32)])\n",
    "for i in range(len(train_data)):\n",
    "  img=train_data[i]\n",
    "  for j in range(len(img)):\n",
    "    train_df.loc[i,'image #']=i\n",
    "    train_df.loc[i,str(j+1)]=img[j].reshape(32*3)\n",
    "\n",
    "train_df.to_csv(\"train_data.csv\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "YpCLOF2Zu11y",
    "outputId": "bdd432e8-5f2b-4cc5-c052-23326e7bd46d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'dev_data=[]\\n\\n\\nfor image in dev_image_names_mal:\\n  try:\\n    im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\\n    im=array(im.resize((32, 32)))\\n    dev_data.append(im)\\n  except:\\n    pass\\n\\nfor image in dev_image_names_ben:\\n    try:\\n      im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\\n      im=array(im.resize((32, 32)))\\n      dev_data.append(im)\\n    except:\\n      pass\\n\\n\\ndev_df=pd.DataFrame(columns=[\\'image #\\']+[str(x+1) for x in range(32)])\\nfor i in range(len(dev_data)):\\n  img=train_data[i]\\n  for j in range(len(img)):\\n    dev_df.loc[i,\\'image #\\']=i\\n    dev_df.loc[i,str(j+1)]=img[j].reshape(32*3)\\n\\ndev_df.to_csv(\"dev_data.csv\")\\n#pd.DataFrame(list(zip(dev_data, dev_labels)), columns =[\\'dev_data\\', \\'dev_labels\\']).to_csv(\"dev_data.csv\")'"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dev_data=[]\n",
    "\n",
    "\n",
    "for image in dev_image_names_mal:\n",
    "  try:\n",
    "    im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\n",
    "    im=array(im.resize((32, 32)))\n",
    "    dev_data.append(im)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "for image in dev_image_names_ben:\n",
    "    try:\n",
    "      im = Image.open(\"/content/gdrive/.shortcut-targets-by-id/1qJ47SkRrR6gtmKvnBstwgxcG-abjnb3a/Kaggle/melanoma/jpeg/train/{}.jpg\".format(image))\n",
    "      im=array(im.resize((32, 32)))\n",
    "      dev_data.append(im)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "\n",
    "dev_df=pd.DataFrame(columns=['image #']+[str(x+1) for x in range(32)])\n",
    "for i in range(len(dev_data)):\n",
    "  img=train_data[i]\n",
    "  for j in range(len(img)):\n",
    "    dev_df.loc[i,'image #']=i\n",
    "    dev_df.loc[i,str(j+1)]=img[j].reshape(32*3)\n",
    "\n",
    "dev_df.to_csv(\"dev_data.csv\")\n",
    "#pd.DataFrame(list(zip(dev_data, dev_labels)), columns =['dev_data', 'dev_labels']).to_csv(\"dev_data.csv\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcRvaJZ3g_7R"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"train_data.csv\")\n",
    "dev_data=pd.read_csv(\"dev_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bhZwQgQEmstO"
   },
   "outputs": [],
   "source": [
    "train_data_list=[]\n",
    "dev_data_list=[]\n",
    "\n",
    "def update_pixels(pixel_n,index_n):\n",
    "  new_array=train_data[pixel_n][index_n].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\n\",\"\").split(\" \")\n",
    "  new_array[:] = [x for x in new_array if x != '']\n",
    "  return array([int(x) for x in new_array]).reshape(32,3)\n",
    "\n",
    "for index, row in train_data.iterrows():\n",
    "    picture_list=[]\n",
    "    for i in range(32): \n",
    "      pixel_index=str(i+1)\n",
    "      new_pixels=update_pixels(pixel_index,index)\n",
    "      picture_list.append(new_pixels)\n",
    "    picture_list=array(picture_list)\n",
    "    train_data_list.append(picture_list)\n",
    "\n",
    "for index, row in dev_data.iterrows():\n",
    "    picture_list=[]\n",
    "    for i in range(32): \n",
    "      pixel_index=str(i+1)\n",
    "      new_pixels=update_pixels(pixel_index,index)\n",
    "      picture_list.append(new_pixels)\n",
    "    picture_list=array(picture_list)\n",
    "    dev_data_list.append(picture_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77JLKkFYaKny"
   },
   "outputs": [],
   "source": [
    "train_data=array(train_data_list)\n",
    "dev_data=array(dev_data_list)\n",
    "X_train = train_data.reshape(train_data.shape[0], 32, 32, 3)\n",
    "X_dev = dev_data.reshape(dev_data.shape[0], 32, 32, 3)\n",
    "X_train = X_train.astype('float32')\n",
    "X_dev = X_dev.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_dev /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(train_labels, 2)\n",
    "Y_dev = np_utils.to_categorical(dev_labels, 2)\n",
    "\n",
    "X_train_svm=[]\n",
    "for i in X_train:\n",
    "  nsamples, nx, ny = i.shape\n",
    "  d2_train_dataset = i.reshape((nsamples*nx*ny))\n",
    "  X_train_svm.append(d2_train_dataset)\n",
    "\n",
    "X_dev_svm=[]\n",
    "for i in X_dev:\n",
    "  nsamples, nx, ny = i.shape\n",
    "  d2_train_dataset = i.reshape((nsamples*nx*ny))\n",
    "  X_dev_svm.append(d2_train_dataset)\n",
    "\n",
    "target_names=[str(x) for x in list(np.unique(dev_labels))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQioMfQni-cH"
   },
   "source": [
    "### Base Model Using Tensorflow, Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qt119h8xuRdQ",
    "outputId": "027a910f-40ce-48e5-8587-77696c662431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpylpwtah5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpylpwtah5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f598df27e10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpylpwtah5', '_session_creation_timeout_secs': 7200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f598df27e10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpylpwtah5', '_session_creation_timeout_secs': 7200}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpylpwtah5/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpylpwtah5/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpylpwtah5/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpylpwtah5/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-08-02T18:30:13Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-08-02T18:30:13Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpylpwtah5/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpylpwtah5/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-08-02-18:30:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-08-02-18:30:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.85484374, global_step = 100, loss = 0.6049458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.85484374, global_step = 100, loss = 0.6049458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.6049458 \n",
      "Accuracy 0.85484374\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/learn/python/learn/estimators/svm.py\n",
    "X = np.array(X_train_svm)\n",
    "Y = np.array(train_labels)\n",
    "\n",
    "X_dev=np.array(X_dev_svm)\n",
    "Y_dev=np.array(dev_labels)\n",
    "\n",
    "example_id = np.array(['%d' % i for i in range(len(Y))])\n",
    "example_id_dev = np.array(['%d' % i for i in range(len(Y_dev))])\n",
    "\n",
    "x_column_name = 'x'\n",
    "example_id_column_name = 'example_id'\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={x_column_name: X, example_id_column_name: example_id},\n",
    "    y=Y,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "dev_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={x_column_name: X_dev, example_id_column_name: example_id_dev},\n",
    "    y=Y_dev,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "svm = tf.contrib.learn.SVM(\n",
    "    example_id_column=example_id_column_name,\n",
    "    feature_columns=(tf.contrib.layers.real_valued_column(\n",
    "        column_name=x_column_name, dimension=49152),),\n",
    "    l2_regularization=1)\n",
    "\n",
    "svm.fit(input_fn=train_input_fn, steps=100)\n",
    "svm_metrics = svm.evaluate(input_fn=dev_input_fn, steps=100)\n",
    "#auc=metrics=[tf.keras.metrics.AUC()]\n",
    "#svm_predictions=[x for x in svm.predict_classes(input_fn=dev_input_fn)]\n",
    "\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(dev_labels, svm_predictions, pos_label=1)\n",
    "#print(\"AUC\",metrics.auc(fpr, tpr))\n",
    "print(\"Loss\", svm_metrics['loss'], \"\\nAccuracy\", svm_metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmySW-3SAONy"
   },
   "source": [
    "### Tensorflow Model with Weights, Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Npp7Wt9szvUS"
   },
   "outputs": [],
   "source": [
    "num_benign_samples=30000\n",
    "num_malignant_samples=500\n",
    "weights=np.array([num_benign_samples/num_malignant_samples for x in range(500)]+[1 for x in range(num_benign_samples)]).astype(np.float32)\n",
    "dev_weights=np.array([1 for i in range(len(Y_dev))]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "L23RaVc9Dq8o",
    "outputId": "e7199e21-c185-4ca4-8661-8c426d02d266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-SQrcP1uANme",
    "outputId": "044e0249-b08e-436e-ef09-b25b33ecc375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpglcb6z0x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpglcb6z0x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f598df27160>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpglcb6z0x', '_session_creation_timeout_secs': 7200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f598df27160>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpglcb6z0x', '_session_creation_timeout_secs': 7200}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Weights weight has shape (128,), expanding to make it 2d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Weights weight has shape (128,), expanding to make it 2d.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/head.py:1838: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/head.py:1838: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpglcb6z0x/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpglcb6z0x/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpglcb6z0x/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpglcb6z0x/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.0014205705.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.0014205705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Weights weight has shape (128,), expanding to make it 2d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Weights weight has shape (128,), expanding to make it 2d.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-08-02T18:30:15Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-08-02T18:30:15Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpglcb6z0x/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpglcb6z0x/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-08-02-18:30:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-08-02-18:30:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.8549219, global_step = 100, loss = 0.44328803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.8549219, global_step = 100, loss = 0.44328803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.44328803 \n",
      "Accuracy 0.8549219\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/learn/python/learn/estimators/svm.py\n",
    "weight_column_name1=\"weight\"\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={x_column_name: X, example_id_column_name: example_id,\"weight\":weights},\n",
    "    y=Y,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "dev_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={x_column_name: X_dev, example_id_column_name: example_id_dev,\"weight\":dev_weights},\n",
    "    y=Y_dev,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "svm = tf.contrib.learn.SVM(\n",
    "    example_id_column=example_id_column_name,\n",
    "    weight_column_name=\"weight\",\n",
    "    feature_columns=(tf.contrib.layers.real_valued_column(\n",
    "        column_name=x_column_name, dimension=49152),),\n",
    "    l2_regularization=1)\n",
    "\n",
    "svm.fit(input_fn=train_input_fn, steps=100)\n",
    "\n",
    "svm_metrics = svm.evaluate(input_fn=dev_input_fn, steps=100)\n",
    "#auc=metrics=[tf.keras.metrics.AUC()]\n",
    "#svm_predictions=[i for i in svm.predict_classes(input_fn=dev_input_fn)]\n",
    "\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(dev_labels, svm_predictions, pos_label=1)\n",
    "#print(\"AUC\",metrics.auc(fpr, tpr))\n",
    "print(\"Loss\", svm_metrics['loss'], \"\\nAccuracy\", svm_metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oL3L3JI4ajIy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rsgMEKq3a0am"
   },
   "source": [
    "### Base Models Using SVM in Scikit Learn with Differing Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xz0r80PdzwBb"
   },
   "source": [
    "Instead of using an even number of examples from each of the benign and malignant datasets, weights will be used in the following models -- giving more weights to the malignant examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "20j6iKqd5MER",
    "outputId": "77d9adf8-1e9e-4a3d-96ed-516f8b261166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.84       584\n",
      "   macro avg       0.43      0.49      0.46       584\n",
      "weighted avg       0.73      0.84      0.78       584\n",
      "\n",
      "AUC 0.493\n",
      "Weights=1, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.46      0.60       500\n",
      "           1       0.16      0.62      0.25        84\n",
      "\n",
      "    accuracy                           0.48       584\n",
      "   macro avg       0.52      0.54      0.43       584\n",
      "weighted avg       0.77      0.48      0.55       584\n",
      "\n",
      "AUC 0.5375238095238095\n",
      "Weights=1, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       500\n",
      "           1       0.14      0.14      0.14        84\n",
      "\n",
      "    accuracy                           0.75       584\n",
      "   macro avg       0.50      0.50      0.50       584\n",
      "weighted avg       0.75      0.75      0.75       584\n",
      "\n",
      "AUC 0.4964285714285714\n",
      "Weights=30, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.21      0.34       500\n",
      "           1       0.17      0.98      0.29        84\n",
      "\n",
      "    accuracy                           0.32       584\n",
      "   macro avg       0.58      0.59      0.32       584\n",
      "weighted avg       0.86      0.32      0.33       584\n",
      "\n",
      "AUC 0.591095238095238\n",
      "Weights=30, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29       500\n",
      "           1       0.17      1.00      0.29        84\n",
      "\n",
      "    accuracy                           0.29       584\n",
      "   macro avg       0.58      0.58      0.29       584\n",
      "weighted avg       0.88      0.29      0.29       584\n",
      "\n",
      "AUC 0.5840000000000001\n",
      "Weights=30, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.28      0.43       500\n",
      "           1       0.17      0.89      0.29        84\n",
      "\n",
      "    accuracy                           0.37       584\n",
      "   macro avg       0.56      0.59      0.36       584\n",
      "weighted avg       0.83      0.37      0.41       584\n",
      "\n",
      "AUC 0.5864285714285715\n",
      "Weights=60, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.28       500\n",
      "           1       0.17      1.00      0.29        84\n",
      "\n",
      "    accuracy                           0.29       584\n",
      "   macro avg       0.58      0.58      0.29       584\n",
      "weighted avg       0.88      0.29      0.29       584\n",
      "\n",
      "AUC 0.583\n",
      "Weights=60, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29       500\n",
      "           1       0.17      1.00      0.29        84\n",
      "\n",
      "    accuracy                           0.29       584\n",
      "   macro avg       0.58      0.58      0.29       584\n",
      "weighted avg       0.88      0.29      0.29       584\n",
      "\n",
      "AUC 0.5840000000000001\n",
      "Weights=60, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.21      0.34       500\n",
      "           1       0.17      0.95      0.29        84\n",
      "\n",
      "    accuracy                           0.31       584\n",
      "   macro avg       0.57      0.58      0.31       584\n",
      "weighted avg       0.85      0.31      0.33       584\n",
      "\n",
      "AUC 0.5791904761904761\n"
     ]
    }
   ],
   "source": [
    "for weight in (1,30,60):\n",
    "  for kern in ('rbf','linear', 'poly'):\n",
    "    weights=[weight for x in range(num_malignant_samples)]+[1 for x in range(num_benign_samples)]\n",
    "    svm =  Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel=kern,gamma='auto'))])\n",
    "    svm.fit(X_train_svm, train_labels, **{'svc__sample_weight': weights})\n",
    "\n",
    "    prediction_svm=svm.predict(X_dev_svm) #predicting with dev_data\n",
    "    print('Weights={}, Kernel={}'.format(weight, kern))\n",
    "    print(classification_report(dev_labels, prediction_svm, target_names=target_names))\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(dev_labels, prediction_svm, pos_label=1)\n",
    "    print(\"AUC\",metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JHSEm6LjbJy"
   },
   "source": [
    "###SVM with PCA and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "w2bH68qYi4P0",
    "outputId": "bd56d2da-b1e9-4ea4-d909-226a73aefb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=30, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       500\n",
      "           1       0.10      0.08      0.09        84\n",
      "\n",
      "    accuracy                           0.76       584\n",
      "   macro avg       0.48      0.48      0.48       584\n",
      "weighted avg       0.74      0.76      0.75       584\n",
      "\n",
      "AUC 0.47866666666666663\n",
      "Weights=30, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=30, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       500\n",
      "           1       0.17      0.05      0.07        84\n",
      "\n",
      "    accuracy                           0.83       584\n",
      "   macro avg       0.52      0.50      0.49       584\n",
      "weighted avg       0.76      0.83      0.79       584\n",
      "\n",
      "AUC 0.5048095238095238\n",
      "Weights=60, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.22      0.36       500\n",
      "           1       0.15      0.79      0.25        84\n",
      "\n",
      "    accuracy                           0.30       584\n",
      "   macro avg       0.50      0.50      0.30       584\n",
      "weighted avg       0.76      0.30      0.34       584\n",
      "\n",
      "AUC 0.5048571428571429\n",
      "Weights=60, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.34      0.48       500\n",
      "           1       0.14      0.63      0.23        84\n",
      "\n",
      "    accuracy                           0.38       584\n",
      "   macro avg       0.49      0.48      0.35       584\n",
      "weighted avg       0.74      0.38      0.45       584\n",
      "\n",
      "AUC 0.4844761904761905\n",
      "Weights=60, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82       500\n",
      "           1       0.12      0.17      0.14        84\n",
      "\n",
      "    accuracy                           0.70       584\n",
      "   macro avg       0.48      0.48      0.48       584\n",
      "weighted avg       0.74      0.70      0.72       584\n",
      "\n",
      "AUC 0.4763333333333334\n",
      "Weights=1, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=30, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.50      0.63       500\n",
      "           1       0.14      0.50      0.22        84\n",
      "\n",
      "    accuracy                           0.50       584\n",
      "   macro avg       0.50      0.50      0.43       584\n",
      "weighted avg       0.75      0.50      0.57       584\n",
      "\n",
      "AUC 0.501\n",
      "Weights=30, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       500\n",
      "           1       0.14      0.18      0.15        84\n",
      "\n",
      "    accuracy                           0.72       584\n",
      "   macro avg       0.50      0.49      0.49       584\n",
      "weighted avg       0.75      0.72      0.73       584\n",
      "\n",
      "AUC 0.49428571428571433\n",
      "Weights=30, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87       500\n",
      "           1       0.12      0.10      0.11        84\n",
      "\n",
      "    accuracy                           0.77       584\n",
      "   macro avg       0.49      0.49      0.49       584\n",
      "weighted avg       0.75      0.77      0.76       584\n",
      "\n",
      "AUC 0.4896190476190477\n",
      "Weights=60, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.24      0.38       500\n",
      "           1       0.15      0.81      0.26        84\n",
      "\n",
      "    accuracy                           0.32       584\n",
      "   macro avg       0.52      0.52      0.32       584\n",
      "weighted avg       0.78      0.32      0.36       584\n",
      "\n",
      "AUC 0.5247619047619048\n",
      "Weights=60, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.40      0.55       500\n",
      "           1       0.15      0.61      0.23        84\n",
      "\n",
      "    accuracy                           0.43       584\n",
      "   macro avg       0.50      0.50      0.39       584\n",
      "weighted avg       0.76      0.43      0.50       584\n",
      "\n",
      "AUC 0.5035714285714286\n",
      "Weights=60, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.63      0.72       500\n",
      "           1       0.13      0.32      0.18        84\n",
      "\n",
      "    accuracy                           0.59       584\n",
      "   macro avg       0.49      0.48      0.45       584\n",
      "weighted avg       0.74      0.59      0.64       584\n",
      "\n",
      "AUC 0.47571428571428576\n",
      "Weights=1, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=30, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.35      0.50       500\n",
      "           1       0.16      0.76      0.27        84\n",
      "\n",
      "    accuracy                           0.41       584\n",
      "   macro avg       0.53      0.56      0.39       584\n",
      "weighted avg       0.79      0.41      0.47       584\n",
      "\n",
      "AUC 0.555952380952381\n",
      "Weights=30, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79       500\n",
      "           1       0.13      0.25      0.17        84\n",
      "\n",
      "    accuracy                           0.66       584\n",
      "   macro avg       0.49      0.49      0.48       584\n",
      "weighted avg       0.75      0.66      0.70       584\n",
      "\n",
      "AUC 0.489\n",
      "Weights=30, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82       500\n",
      "           1       0.16      0.25      0.19        84\n",
      "\n",
      "    accuracy                           0.70       584\n",
      "   macro avg       0.51      0.51      0.51       584\n",
      "weighted avg       0.76      0.70      0.73       584\n",
      "\n",
      "AUC 0.514\n",
      "Weights=60, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.22      0.36       500\n",
      "           1       0.16      0.88      0.27        84\n",
      "\n",
      "    accuracy                           0.32       584\n",
      "   macro avg       0.54      0.55      0.32       584\n",
      "weighted avg       0.81      0.32      0.35       584\n",
      "\n",
      "AUC 0.5524761904761905\n",
      "Weights=60, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.31      0.45       500\n",
      "           1       0.15      0.73      0.25        84\n",
      "\n",
      "    accuracy                           0.37       584\n",
      "   macro avg       0.51      0.52      0.35       584\n",
      "weighted avg       0.77      0.37      0.42       584\n",
      "\n",
      "AUC 0.5160952380952382\n",
      "Weights=60, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.57      0.69       500\n",
      "           1       0.15      0.46      0.23        84\n",
      "\n",
      "    accuracy                           0.55       584\n",
      "   macro avg       0.51      0.52      0.46       584\n",
      "weighted avg       0.76      0.55      0.62       584\n",
      "\n",
      "AUC 0.5161428571428572\n",
      "Weights=1, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.85       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.85      0.79       584\n",
      "\n",
      "AUC 0.497\n",
      "Weights=1, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=30, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.29      0.44       500\n",
      "           1       0.17      0.88      0.29        84\n",
      "\n",
      "    accuracy                           0.38       584\n",
      "   macro avg       0.55      0.59      0.37       584\n",
      "weighted avg       0.83      0.38      0.42       584\n",
      "\n",
      "AUC 0.5854761904761905\n",
      "Weights=30, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73       500\n",
      "           1       0.14      0.36      0.20        84\n",
      "\n",
      "    accuracy                           0.60       584\n",
      "   macro avg       0.50      0.50      0.47       584\n",
      "weighted avg       0.75      0.60      0.66       584\n",
      "\n",
      "AUC 0.4985714285714286\n",
      "Weights=30, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76       500\n",
      "           1       0.16      0.38      0.23        84\n",
      "\n",
      "    accuracy                           0.63       584\n",
      "   macro avg       0.51      0.53      0.49       584\n",
      "weighted avg       0.76      0.63      0.68       584\n",
      "\n",
      "AUC 0.5254761904761904\n",
      "Weights=60, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.19      0.31       500\n",
      "           1       0.16      0.94      0.28        84\n",
      "\n",
      "    accuracy                           0.30       584\n",
      "   macro avg       0.56      0.56      0.30       584\n",
      "weighted avg       0.84      0.30      0.31       584\n",
      "\n",
      "AUC 0.5642380952380952\n",
      "Weights=60, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.32      0.46       500\n",
      "           1       0.15      0.74      0.25        84\n",
      "\n",
      "    accuracy                           0.38       584\n",
      "   macro avg       0.52      0.53      0.36       584\n",
      "weighted avg       0.77      0.38      0.43       584\n",
      "\n",
      "AUC 0.527047619047619\n",
      "Weights=60, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.47      0.61       500\n",
      "           1       0.15      0.57      0.24        84\n",
      "\n",
      "    accuracy                           0.48       584\n",
      "   macro avg       0.51      0.52      0.42       584\n",
      "weighted avg       0.76      0.48      0.56       584\n",
      "\n",
      "AUC 0.5197142857142857\n",
      "Weights=1, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.85       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.85      0.79       584\n",
      "\n",
      "AUC 0.496\n",
      "Weights=1, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=1, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       500\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.86       584\n",
      "   macro avg       0.43      0.50      0.46       584\n",
      "weighted avg       0.73      0.86      0.79       584\n",
      "\n",
      "AUC 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights=30, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.23      0.38       500\n",
      "           1       0.17      0.94      0.29        84\n",
      "\n",
      "    accuracy                           0.34       584\n",
      "   macro avg       0.57      0.59      0.33       584\n",
      "weighted avg       0.85      0.34      0.36       584\n",
      "\n",
      "AUC 0.5872380952380952\n",
      "Weights=30, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.61      0.72       500\n",
      "           1       0.16      0.44      0.24        84\n",
      "\n",
      "    accuracy                           0.59       584\n",
      "   macro avg       0.51      0.53      0.48       584\n",
      "weighted avg       0.77      0.59      0.65       584\n",
      "\n",
      "AUC 0.5272380952380952\n",
      "Weights=30, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.57      0.69       500\n",
      "           1       0.14      0.40      0.21        84\n",
      "\n",
      "    accuracy                           0.55       584\n",
      "   macro avg       0.49      0.49      0.45       584\n",
      "weighted avg       0.75      0.55      0.62       584\n",
      "\n",
      "AUC 0.48938095238095236\n",
      "Weights=60, Kernel=rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.17      0.29       500\n",
      "           1       0.17      0.98      0.28        84\n",
      "\n",
      "    accuracy                           0.29       584\n",
      "   macro avg       0.57      0.57      0.29       584\n",
      "weighted avg       0.86      0.29      0.29       584\n",
      "\n",
      "AUC 0.5740952380952381\n",
      "Weights=60, Kernel=linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.30      0.45       500\n",
      "           1       0.16      0.77      0.26        84\n",
      "\n",
      "    accuracy                           0.37       584\n",
      "   macro avg       0.52      0.54      0.36       584\n",
      "weighted avg       0.78      0.37      0.43       584\n",
      "\n",
      "AUC 0.538904761904762\n",
      "Weights=60, Kernel=poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.36      0.51       500\n",
      "           1       0.16      0.70      0.25        84\n",
      "\n",
      "    accuracy                           0.41       584\n",
      "   macro avg       0.52      0.53      0.38       584\n",
      "weighted avg       0.77      0.41      0.47       584\n",
      "\n",
      "AUC 0.5311904761904761\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "for pca_n in (1,3,5,7,9):\n",
    "  pca = PCA(n_components=pca_n) #PCA with 3 dimensions\n",
    "  pca.fit(X_train_svm) \n",
    "  pca_train = pca.transform(X_train_svm) #tra nsform train data to 5 dimensions\n",
    "  pca_test = pca.transform(X_dev_svm) \n",
    "\n",
    "  #weight=60\n",
    "  for weight in (1,30,60):\n",
    "    for kern in ('rbf','linear', 'poly'):\n",
    "      weights=[weight for x in range(num_malignant_samples)]+[1 for x in range(num_benign_samples)]\n",
    "      svm =  Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel=kern,gamma='auto'))])\n",
    "      svm.fit(pca_train, train_labels, **{'svc__sample_weight': weights})\n",
    "\n",
    "      prediction_svm=svm.predict(pca_test) #predicting with dev_data\n",
    "      print('Weights={}, Kernel={}'.format(weight, kern))\n",
    "      print(classification_report(dev_labels, prediction_svm, target_names=target_names))\n",
    "\n",
    "      fpr, tpr, thresholds = metrics.roc_curve(dev_labels, prediction_svm, pos_label=1)\n",
    "      print(\"AUC\",metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mE0eboezbOh"
   },
   "source": [
    "Looking at the results for the different SVM kernels, it appears rbf or poly will work best. Increasing the weights appeared to increase the AUC measure. The sklearn SVM models do not work as well as the tensor flow model. I will work on a more custom tensor flow model soon."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Basic SVM Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
