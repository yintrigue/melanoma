{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"logistics_keras.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"toc-autonumbering":true,"toc-showcode":false,"toc-showmarkdowntxt":false,"toc-showtags":false},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Uh6GnIf-nhQz"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ARU6bJo8bH6_"},"source":["## Imports"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FtXKZWje7XOG","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595293004096,"user_tz":420,"elapsed":271,"user":{"displayName":"Tim Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMh4iph3mxnXQ-zbxwzekj-ovpu-c0cAOBzt1b=s64","userId":"17136390159455304905"}},"outputId":"d9048cb1-5b03-4baa-877b-42c3c076f1f8"},"source":["import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import classification_report\n","\n","import tensorflow.keras as keras\n","from tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall\n","from tensorflow.train import Feature, Features, Example\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, InputLayer\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras import applications\n","from tensorflow.keras import callbacks\n","from tensorflow.keras.models import Sequential\n","\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import numpy as np\n","import pandas as pd\n","\n","import re\n","import math\n","import os\n","import sys\n","import warnings\n","import logging\n","import random\n","\n","from datetime import datetime\n","from IPython.display import display \n","from io import BytesIO\n","from PIL import Image\n","from skimage import io\n","from typing import List, Tuple\n","\n","# local vs. colab\n","IS_LOCAL = False\n","\n","if IS_LOCAL:\n","    # jupyter offline\n","    PATH_KAGGLE_MEL = './../kaggle_symlink_offline/melanoma/'\n","    REPO_ROOT = './../../'\n","    REPO_TEMP = REPO_ROOT + 'temp/'\n","    TFREC_DIR = REPO_ROOT + 'tim/kaggle_symlink_offline/melanoma/tfrecords/triple_stra_{}/'\n","else:\n","    # http://tiny.cc/8jjjsz\n","    # loading from Kaggle to save $$$ (vs. loading from my own GCS)\n","    KAGGLE_TFREC_GCS ={\n","        128: 'gs://kds-659708bf9143f303ebfd1c862eb9e842090662d9004190208d007cc9',\n","        192: 'gs://kds-f53b5775dce9868747163621afd1adc2815412f220130261292837a3',\n","        256: 'gs://kds-f64cfd42bcb769b2eeeecd53d5a52df83d43c19c1184989ed762e30f',\n","        384: 'gs://kds-e73569ee9d44308363027e79908294593e80b1e12e18e57ef065397c',\n","        512: 'gs://kds-4f5e437bc05e29f3e95419fa289ea3a6b01ac2fefcb772ca07cc3b5f',\n","        768: 'gs://kds-49b793da52a884d00e33c11613f3f24261d8e53e1b8c16de8c868509'}\n","\n","    # colab online\n","    PATH_KAGGLE_MEL = '/content/gdrive/My Drive/Kaggle/melanoma/'\n","    REPO_ROOT = '/content/gdrive/My Drive/melanoma/'\n","    REPO_TEMP = REPO_ROOT + 'temp/'\n","    \n","    # mount google drive only on colab\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","warnings.filterwarnings(\"ignore\") # suppress warning messages\n","plt.style.use('ggplot')\n","\n","PROCESSOR = \"GPU\" if IS_LOCAL else \"TPU\"\n","SEED = 207 # used for creating k-fold"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WaD7pd78Tq4B","colab_type":"text"},"source":["## Initializing TPU"]},{"cell_type":"code","metadata":{"id":"efaiB1oVTq4C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":782},"executionInfo":{"status":"ok","timestamp":1595293059511,"user_tz":420,"elapsed":52979,"user":{"displayName":"Tim Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMh4iph3mxnXQ-zbxwzekj-ovpu-c0cAOBzt1b=s64","userId":"17136390159455304905"}},"outputId":"d2125f9a-5a69-4f0f-8faf-b964a4a4c71d"},"source":["if PROCESSOR == \"TPU\":\n","    print(\"connecting to TPU...\")\n","    try:\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        print('Running on TPU: ', tpu.master())\n","    except ValueError:\n","        print(\"Error: Unable to connect to TPU...\")\n","        tpu = None\n","\n","    if tpu:\n","        try:\n","            print(\"Initializing TPU...\")\n","            tf.config.experimental_connect_to_cluster(tpu)\n","            tf.tpu.experimental.initialize_tpu_system(tpu)\n","            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","            print(\"TPU initialized!\")\n","        except _:\n","            print(\"Error: Failed to initialize TPU...\")\n","    else:\n","        PROCESSOR = \"GPU\"\n","\n","if PROCESSOR != \"TPU\":\n","    print(\"Using default strategy for CPU/GPU...\")\n","    strategy = tf.distribute.get_strategy()\n","\n","if PROCESSOR == \"GPU\":\n","    print(\"# of GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","            \n","# https://tinyurl.com/yao4obsb\n","# A single Cloud TPU device consists of four chips, each of which has two TPU cores. \n","# Therefore, for efficient utilization of Cloud TPU, a program should make use of \n","# each of the eight cores.\n","REPLICAS = strategy.num_replicas_in_sync\n","print(f'# of replicatas in sync: {REPLICAS}')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["connecting to TPU...\n","Running on TPU:  grpc://10.121.33.2:8470\n","Initializing TPU...\n","INFO:tensorflow:Initializing the TPU system: grpc://10.121.33.2:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.121.33.2:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["TPU initialized!\n","# of replicatas in sync: 8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2Is06rWHTq4G","colab_type":"text"},"source":["## Utility Functions"]},{"cell_type":"code","metadata":{"id":"kvebEXbmTq4G","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595294256284,"user_tz":420,"elapsed":397,"user":{"displayName":"Tim Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMh4iph3mxnXQ-zbxwzekj-ovpu-c0cAOBzt1b=s64","userId":"17136390159455304905"}}},"source":["def read_labeled_tfrecord(example: Example) -> Tuple['tf.string', 'tf.int64']:\n","    \"\"\"Extract image & label from the tfrecord.\n","    \"\"\"\n","    tfrec_format = {\n","        'image'                        : tf.io.FixedLenFeature([], tf.string),\n","        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n","        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n","        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n","        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n","        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n","        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n","        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n","    }           \n","    example = tf.io.parse_single_example(example, tfrec_format)\n","    return example['image'], example['target']\n","\n","def read_unlabeled_tfrecord(example: Example, \n","                            return_img_name: bool) -> Tuple['tf.string', 'tf.int64']:\n","    \"\"\"Label is unavailable, extract image & image name from the tfrecord.\n","    \"\"\"\n","    tfrec_format = {\n","        'image'                        : tf.io.FixedLenFeature([], tf.string),\n","        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n","    }\n","    example = tf.io.parse_single_example(example, tfrec_format)\n","    if return_img_name:\n","        return example['image'], example['image_name']\n","    else:\n","        return example['image'], 0\n","\n","def aug_image(img, augment=True, dim=256):\n","    \"\"\"Apply random transformation.\n","    \"\"\"\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.cast(img, tf.float32) / 255.0\n","    \n","    if augment:\n","        img = tf.image.random_flip_left_right(img)\n","        img = tf.image.random_hue(img, 0.01)\n","        img = tf.image.random_saturation(img, 0.7, 1.3)\n","        img = tf.image.random_contrast(img, 0.8, 1.2)\n","        img = tf.image.random_brightness(img, 0.1)\n","        img = tf.image.random_flip_up_down(img)\n","        img = tf.clip_by_value(img, 0.0, 1.0)\n","                      \n","    img = tf.reshape(img, [dim,dim, 3])\n","            \n","    return img\n","\n","def count_examples(file_names: List[str]):\n","    \"\"\"Note that the name of each tfrecord file is sufixed with the number of \n","    images included.\n","    \"\"\"\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(f).group(1)) \n","         for f in file_names]\n","    return np.sum(n)\n","                  \n","def get_dataset(tfrec_files: List[str], \n","                dim: int,\n","                batch_size: int = 16,\n","                augment: bool = False, \n","                shuffle: bool = False, \n","                repeat: bool = False, \n","                labeled: bool = True, \n","                return_img_names: bool = True,\n","                drop_remainder: bool = False,\n","                replicas: int = strategy.num_replicas_in_sync) -> Tuple[tf.data.TFRecordDataset, int]:\n","    \"\"\"Return a TFRecordDataset by loading tfrecord files.\n","    Args:\n","        tfrec_files (List[str]): List of paths to the tfrecord files.\n","    Returns:\n","        [0](TFRecordDataset): Two possible column combinations... \n","            - 'image' & 'target' for training dataset\n","            - 'image' & 'image_name' for test dataset\n","        [1](int): Number of steps to complete an epoch.\n","    \"\"\"\n","    \n","    AUTO = tf.data.experimental.AUTOTUNE\n","    ds = tf.data.TFRecordDataset(tfrec_files, \n","                                 num_parallel_reads=AUTO)\n","    ds = ds.cache()\n","    \n","    if repeat:\n","        ds = ds.repeat()\n","    \n","    if shuffle: \n","        ds = ds.shuffle(buffer_size=1024) # 1024 to optimize TPU performance\n","        opt = tf.data.Options()\n","        opt.experimental_deterministic = False # ensure a true random shuffle\n","        ds = ds.with_options(opt)\n","    \n","    if labeled: \n","        # extract image & label\n","        # ds inlcudes just one column of examples\n","        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n","    else:\n","        # extract image & image name\n","        # ds inlcudes just one column of examples\n","        map_ = lambda example: read_unlabeled_tfrecord(example, return_img_names)\n","        ds = ds.map(map_, num_parallel_calls=AUTO)      \n","    \n","    # transform image\n","    # ds has two columns: \"image (intf.string)\" and \"label or image name\"\n","    map_ = lambda img, _: (aug_image(img, augment=augment, dim=dim), _)\n","    ds = ds.map(map_, num_parallel_calls=AUTO)\n","    \n","    # https://tinyurl.com/yao4obsb\n","    # A single Cloud TPU device consists of four chips, each of which has two TPU cores. \n","    # Therefore, for efficient utilization of Cloud TPU, a program should make use of \n","    # each of the eight cores.\n","    #\n","    # https://tinyurl.com/y99kjyh5\n","    # Model processing performance\n","    # For optimum memory usage, use the largest batch size that will fit in memory. \n","    # Each TPU core uses a 128 x 128 memory cell matrix for processing. In general, \n","    # your batch sized should be evenly divisible by 128 to most effectively use the TPU memory.\n","    #\n","    # https://tinyurl.com/yawn2acn\n","    # Batch Size Too Small\n","    # The batch size of any model should always be at least 64 (8 per TPU core) \n","    # because TPU always pads the tensors to this size. The ideal batch size when \n","    # training on the TPU is 1024 (128 per TPU core), since this eliminates inefficiencies \n","    # related to memory transfer and padding.\n","    #\n","    # https://tinyurl.com/y9nojpa2\n","    # Minimal requirement: A multiple of 8!\n","    if PROCESSOR == 'TPU':\n","        if batch_size < 64:\n","            # better\n","            print('Warning: Batch size {} is smaller than 64...'.format(batch_size))\n","        if batch_size % 8 > 0:\n","            # min requirement\n","            print('Error: Batch size {} is not a multiple of 8...'.format(batch_size))\n","    ds = ds.batch(batch_size, drop_remainder=drop_remainder) \n","    \n","    num_images = count_examples(tfrec_files)\n","    steps = num_images // batch_size\n","    if num_images % batch_size > 0:\n","        # require one more step to loop through the entire dataset\n","        steps += 1\n","    \n","    # From tf doc (https://tinyurl.com/yavczqkr):\n","    # Most dataset input pipelines should end with a call to prefetch. This allows \n","    # later elements to be prepared while the current element is being processed. This \n","    # often improves latency and throughput, at the cost of using additional memory to \n","    # store prefetched elements.\n","    ds = ds.prefetch(AUTO)\n","    \n","    return ds, steps\n","\n","def build_logistics(dim: int, \n","                    sig_thd: float = 0.5,\n","                    lr: float = 0.001,\n","                    label_smoothing: float = 0.05) -> Sequential:\n","\n","    loss_func = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n","    \n","    m = Sequential()\n","    m.add(InputLayer(input_shape=(dim, dim, 3)))\n","    m.add(Flatten())\n","    m.add(Dense(1, activation='sigmoid')) \n","    \n","    # compile model\n","    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n","              loss=loss_func, \n","              metrics=[AUC(),\n","                       BinaryAccuracy(threshold=sig_thd),\n","                       Recall(thresholds=sig_thd)])\n","    return m"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ul8UbYs9Tq4e","colab_type":"text"},"source":["# Logistic Regression Using Keras"]},{"cell_type":"markdown","metadata":{"id":"O_JZ-jpGTq4e","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"eZnXP9_MTq4e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1595295040698,"user_tz":420,"elapsed":127790,"user":{"displayName":"Tim Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMh4iph3mxnXQ-zbxwzekj-ovpu-c0cAOBzt1b=s64","userId":"17136390159455304905"}},"outputId":"21d8efbd-6e4f-4156-85b0-0a78e21b97a1"},"source":["BATCH_SIZE = 64\n","EPOCH = 5\n","IMG_SIZE = 512 # 128, 192, 256, 384, 512, 768, 1024\n","\n","SIGMOID_THD = 0.2\n","DEV_SET_FILE_COUNT = 3\n","LABEL_SMOOTHING = 0.05\n","\n","LEARN_RATE = 0.001\n","SIGMOID_THD = 0.2\n","\n","# prep datasets\n","if IS_LOCAL:\n","    TFREC_TEST_SET = tf.io.gfile.glob(TFREC_DIR.format(IMG_SIZE) + 'train*.tfrec')\n","else:\n","    TFREC_TRAIN_SET = tf.io.gfile.glob(KAGGLE_TFREC_GCS[IMG_SIZE] + '/train*.tfrec')\n","random.shuffle(TFREC_TRAIN_SET)\n","TFREC_DEV_SET = TFREC_TRAIN_SET[:DEV_SET_FILE_COUNT]\n","TFREC_TRAIN_SET = TFREC_TRAIN_SET[DEV_SET_FILE_COUNT:]\n","\n","SAVE_DIR = REPO_ROOT + 'tim/cnn/_saves/cnn_efn/'\n","\n","# --------------------------------------------------------------------------\n","# BUILD MODEL\n","\n","print('Building model...')\n","keras.backend.clear_session() \n","with strategy.scope():\n","    model = build_logistics(dim=IMG_SIZE,\n","                            sig_thd=SIGMOID_THD,\n","                            lr=LEARN_RATE,\n","                            label_smoothing = LABEL_SMOOTHING)\n","\n","# create save dir\n","st = datetime.utcnow().strftime('logi_utc_%m%d_%H%M%S')\n","save_dir = SAVE_DIR + st\n","os.mkdir(save_dir)\n","save_dir += '/'\n","        \n","# --------------------------------------------------------------------------\n","# TRAINING\n","\n","print('Training...')\n","ds_train, steps_train = get_dataset(TFREC_TRAIN_SET, \n","                                    augment=False, \n","                                    shuffle=True, \n","                                    repeat=True,\n","                                    dim=IMG_SIZE, \n","                                    batch_size=BATCH_SIZE)\n","history = model.fit(ds_train, \n","                    epochs=EPOCH, \n","                    steps_per_epoch=steps_train,\n","                    verbose=1)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Building model...\n","Training...\n","Epoch 1/5\n","408/409 [============================>.] - ETA: 0s - binary_accuracy: 0.9428 - auc: 0.5063 - recall: 0.0546 - loss: 217.3705WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r409/409 [==============================] - 16s 38ms/step - binary_accuracy: 0.9429 - auc: 0.5062 - recall: 0.0543 - loss: 216.9324\n","Epoch 2/5\n","408/409 [============================>.] - ETA: 0s - binary_accuracy: 0.9435 - auc: 0.5022 - recall: 0.0446 - loss: 238.1614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r409/409 [==============================] - 15s 37ms/step - binary_accuracy: 0.9435 - auc: 0.5022 - recall: 0.0445 - loss: 237.6111\n","Epoch 3/5\n","408/409 [============================>.] - ETA: 0s - binary_accuracy: 0.9414 - auc: 0.4994 - recall: 0.0414 - loss: 209.8053WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stderr"},{"output_type":"stream","text":["409/409 [==============================] - 13s 33ms/step - binary_accuracy: 0.9415 - auc: 0.4994 - recall: 0.0413 - loss: 210.3313\n","Epoch 4/5\n","409/409 [==============================] - ETA: 0s - binary_accuracy: 0.9439 - auc: 0.5075 - recall: 0.0550 - loss: 249.6022WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stderr"},{"output_type":"stream","text":["409/409 [==============================] - 13s 33ms/step - binary_accuracy: 0.9439 - auc: 0.5075 - recall: 0.0550 - loss: 249.6022\n","Epoch 5/5\n","408/409 [============================>.] - ETA: 0s - binary_accuracy: 0.9433 - auc: 0.5127 - recall: 0.0647 - loss: 203.2343WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r409/409 [==============================] - 14s 33ms/step - binary_accuracy: 0.9434 - auc: 0.5126 - recall: 0.0644 - loss: 203.7991\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cpb_Ox2N1CUG","colab_type":"text"},"source":["## Predicting"]},{"cell_type":"code","metadata":{"id":"QOEXCmdprrxb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1595295572377,"user_tz":420,"elapsed":21559,"user":{"displayName":"Tim Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMh4iph3mxnXQ-zbxwzekj-ovpu-c0cAOBzt1b=s64","userId":"17136390159455304905"}},"outputId":"a30e8238-0fe2-4fca-8abc-31e03ebf5ac9"},"source":["print('\\nPredicting...')\n","# perform TTA\n","ds_valid, steps_valid = get_dataset(TFREC_DEV_SET,\n","                                    labeled=False,\n","                                    return_img_names=False,\n","                                    augment=False,\n","                                    repeat=True,\n","                                    shuffle=False,\n","                                    dim=IMG_SIZE,\n","                                    batch_size=BATCH_SIZE)\n","\n","preds = model.predict(ds_valid,\n","                        steps=steps_valid,\n","                        verbose=1)\n","\n","# cut off the \"reminders\" in the last batch \n","ct_valid = count_examples(TFREC_DEV_SET)\n","preds = preds[:ct_valid,] \n","\n","# get oof probabilities\n","preds_reshape = preds\n","preds_avg = np.mean(preds_reshape, axis=1)\n","\n","# get oof targets\n","ds_targets, _ = get_dataset(TFREC_DEV_SET, \n","                            augment=False, \n","                            repeat=False, \n","                            labeled=True, \n","                            dim=IMG_SIZE,\n","                            batch_size=BATCH_SIZE)\n","targets = [target.numpy() for img, target in iter(ds_targets.unbatch())]\n","targets = np.array(targets)\n","\n","# print oof auc\n","auc_no_tta = np.max(history.history['auc'])\n","print('AUC =', auc_no_tta)\n","\n","# print report\n","pred_labels = np.zeros(preds_avg.shape[0])\n","pred_labels[preds_avg >= SIGMOID_THD] = 1\n","report = classification_report(targets, pred_labels, output_dict=True)\n","print(classification_report(targets, pred_labels))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["\n","Predicting...\n","103/103 [==============================] - 3s 30ms/step\n","AUC = 0.5126039981842041\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99      6426\n","           1       0.00      0.00      0.00       116\n","\n","    accuracy                           0.98      6542\n","   macro avg       0.49      0.50      0.50      6542\n","weighted avg       0.96      0.98      0.97      6542\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6olFY_dYTq4Y","colab_type":"text"},"source":["## Testing Different Sigmoid Thresholds "]},{"cell_type":"code","metadata":{"id":"dwTJuxZHTq4Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":578},"executionInfo":{"status":"ok","timestamp":1595295585999,"user_tz":420,"elapsed":359,"user":{"displayName":"Tim Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMh4iph3mxnXQ-zbxwzekj-ovpu-c0cAOBzt1b=s64","userId":"17136390159455304905"}},"outputId":"6497c00b-ab3b-4d34-972d-f05059e65330"},"source":["THDS = [0.1, 0.2, 0.5]\n","\n","for thd in THDS:\n","    pred_labels = np.zeros(preds_avg.shape[0])\n","    pred_labels[preds_avg >= thd] = 1\n","    report = classification_report(targets, pred_labels, output_dict=True)\n","    print(\"\\nSigmoid THD = {:.2f}:\".format(thd))\n","    print(classification_report(targets, pred_labels))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["\n","Sigmoid THD = 0.10:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99      6426\n","           1       0.00      0.00      0.00       116\n","\n","    accuracy                           0.98      6542\n","   macro avg       0.49      0.50      0.50      6542\n","weighted avg       0.96      0.98      0.97      6542\n","\n","\n","Sigmoid THD = 0.20:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99      6426\n","           1       0.00      0.00      0.00       116\n","\n","    accuracy                           0.98      6542\n","   macro avg       0.49      0.50      0.50      6542\n","weighted avg       0.96      0.98      0.97      6542\n","\n","\n","Sigmoid THD = 0.50:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99      6426\n","           1       0.00      0.00      0.00       116\n","\n","    accuracy                           0.98      6542\n","   macro avg       0.49      0.50      0.50      6542\n","weighted avg       0.96      0.98      0.97      6542\n","\n"],"name":"stdout"}]}]}